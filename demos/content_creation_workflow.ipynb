{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Creating Content from Webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:**\n",
    "\n",
    "This notebook demoes how a simple workflow of sequential requests to large language models can be leveraged to create multiple pieces of content from an arbitrary webpage.\n",
    "\n",
    "This workflow consists of three sequential steps:\n",
    "1. Generate a summary of desired webpage\n",
    "2. Structure the summary according to a user-defined outline.\n",
    "3. Create a social media post from structured summary with custom persona.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "This demo uses the OpenAI Chat API and, thus, requires an OpenAI API key.\n",
    "\n",
    "**Disclaimer:**\n",
    "\n",
    "This notebook is strictly for educational purposes. Users should employ it responsibly, ensuring accuracy, respecting privacy and copyright, and avoiding the dissemination of misinformation. Always consider the ethical implications and context of the generated content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Load and parse HTML webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start our workflow, we extract the text content from the desired webpage, focusing on paragraphs and headers, to use downstream. We use the Llama 2 announcement from Meta AI in this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Introducing LLaMA  A foundational  65 billion parameter large language model\n",
       "\n",
       "February 24  2023\n",
       "\n",
       "UPDATE  We just launched Llama 2   for more information on the latest see our blog post on Llama 2  \n",
       "\n",
       "As part of Meta s commitment to open science  today we are publicly releasing LLaMA  Large Language Model Meta AI   a state of the art foundational large language model designed to help researchers advance their work in this subfield of AI  Smaller  more performant models such as LLaMA enable others in the research community who don t have access to large amounts of infrastructure to study these models  further democratizing access in this important  fast changing field \n",
       "\n",
       "Training smaller foundation models like LLaMA is desirable in the large language model space because it requires far less computing power and resources to test new approaches  validate others  work  and explore new use cases  Foundation models train on a large set of unlabeled data  which makes them ideal for fine tuning for a variety of tasks  We are making LLaMA available at several sizes  7B  13B  33B  and 65B parameters  and also sharing a LLaMA model card that details how we built the model in keeping with our app"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text from webpage\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from genaipy.extractors.web import extract_tags_contents\n",
    "\n",
    "URL = \"https://ai.meta.com/blog/large-language-model-llama-meta-ai/\"\n",
    "TAGS = [\"p\", \"h1\"]\n",
    "\n",
    "text = extract_tags_contents(url=URL, tags=TAGS)\n",
    "Markdown(text[:1200]) # Display first 1200 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step [1/3]: Generate Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step of the workflow, we provide the input text sample to `GPT-3.5-turbo` and request it to generate a 150 words long summary. This step serves as the foundation for the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Meta has publicly released LLaMA, a large language model designed to help researchers in the field of AI. Smaller models like LLaMA require less computing power and resources, making them more accessible for studying and fine-tuning. LLaMA is available in different sizes, ranging from 7B to 65B parameters. Large language models have shown significant potential in various tasks, but limited access to them hinders progress in understanding their workings and addressing issues like bias and misinformation. LLaMA is trained on a large dataset and can be applied to different use cases. The model is released under a noncommercial license for research purposes, and access is granted on a case-by-case basis. Collaboration among the AI community is encouraged to develop responsible guidelines for large language models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from genaipy.openai_apis.chat import get_chat_response\n",
    "from genaipy.prompts.build_prompt import build_prompt\n",
    "from genaipy.prompts.generate_summaries import SUMMARY_PROMPT_TPL\n",
    "\n",
    "prompt = build_prompt(template=SUMMARY_PROMPT_TPL, text=text, max_words=150)\n",
    "\n",
    "summary = get_chat_response(prompt=prompt, temperature=0.2)\n",
    "Markdown(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step [2/3]: Structure Summary with Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second step of the workflow, we use the generated summary and utilize `GPT-3.5-turbo` to structure it according to a custom outline. Notably, this structured outline is completely customizable to the requirements of the use case (e.g., meeting minutes, reports, etc.).\n",
    "\n",
    "Here, we opted for a basic outline for structuring summaries displayed below. Since the structured summary is in `Markdown`, it can be directly saved and displayed in many text editors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [Short Title]\n",
      "\n",
      "## Summary\n",
      "(Exactly 1 sentence long summary of the main topic and objective.)\n",
      "\n",
      "## Key points \n",
      "(bulleted list of 3-5 main points.)\n",
      "- [Key insight 1]\n",
      "- [Key insight 2]\n",
      "- [Key insight 3]\n",
      "- ... (only if needed)\n",
      "\n",
      "## Key concepts\n",
      "(bulleted list of exactly 3-5 main concepts and entities.)\n",
      "- [Key concept/entity 1]\n",
      "- [Key concept/entity 2]\n",
      "- [Key concept/entity 3]\n",
      "- ... (only if needed)\n"
     ]
    }
   ],
   "source": [
    "# Load structured outline\n",
    "\n",
    "from genaipy.outlines.basic_summary_outline import BASIC_SUMMARY_OUTLINE\n",
    "\n",
    "tpl = BASIC_SUMMARY_OUTLINE.strip()\n",
    "print(tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "# LLaMA: A Large Language Model for AI Research\n",
       "\n",
       "## Summary\n",
       "LLaMA is a large language model developed by Meta to assist researchers in the field of AI by providing a more accessible and resource-efficient option for studying and fine-tuning language models.\n",
       "\n",
       "## Key points\n",
       "- LLaMA is a smaller language model that requires less computing power and resources, making it easier for researchers to work with.\n",
       "- The model is available in different sizes, ranging from 7B to 65B parameters, allowing researchers to choose the appropriate scale for their needs.\n",
       "- Limited access to large language models has hindered progress in understanding their workings, addressing bias, and combating misinformation.\n",
       "- LLaMA is trained on a large dataset and can be applied to various use cases, enhancing its versatility and applicability.\n",
       "- The model is released under a noncommercial license for research purposes, and access is granted on a case-by-case basis.\n",
       "\n",
       "## Key concepts\n",
       "- Large language models: Advanced AI models designed to process and generate human-like text.\n",
       "- Accessibility: Making resources and tools more available and easier to use for researchers.\n",
       "- Bias and misinformation: Issues related to the presence of prejudices and false information in language models and their outputs.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate structured summary\n",
    "\n",
    "from genaipy.prompts.style_texts import STYLE_TEXT_TPL\n",
    "\n",
    "style_prompt = build_prompt(template=STYLE_TEXT_TPL, text=summary, tpl=tpl)\n",
    "\n",
    "styled_summary = get_chat_response(prompt=style_prompt, temperature=0) \n",
    "Markdown(styled_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step [3/3]: Generate Social Media Post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step of the workflow, we generate a social media post from the structured summary using `GPT-4-turbo`. \n",
    "Notably, we set a custom role for the LLM via the system message to tailor the style and tone of the post.\n",
    "\n",
    "In this case, we set the LLM's role to a  professional content creator on Linkedin excelling at communicating complex AI topics in a simple way. Feel free to change the system message below, to explore different types of social media posts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are an expert content creator on LinkedIn. You excell at communicating complex topics in Generative AI in a simple and professional way."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define custom role\n",
    "\n",
    "system_message = \"You are an expert content creator on LinkedIn. You excell at communicating complex topics in Generative AI in a simple and professional way.\"\n",
    "Markdown(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "üöÄ Thrilled to share insights on Meta's LLaMA, a game-changer in AI research!\n",
       "\n",
       "üîç **Understanding LLaMA:**\n",
       "As a passionate advocate for democratizing AI, I'm excited about LLaMA's potential. It's a lean, mean, AI research machine, tailored for accessibility and efficiency.\n",
       "\n",
       "üåü **Why LLaMA Stands Out:**\n",
       "- Scaled for simplicity: With models from 7B to 65B parameters, LLaMA is fit for various research scopes.\n",
       "- Democratizing AI: Finally, a language model that broadens research horizons without the computational cost barrier.\n",
       "- A step towards transparency: By addressing AI biases and misinformation, LLaMA paves the way for more ethical AI.\n",
       "\n",
       "üîê **Access & Use:**\n",
       "Leveraging LLaMA is a breeze under its noncommercial research license, though it's a case-by-case deal.\n",
       "\n",
       "Let's embrace this stride in AI‚Äîmore accessible, less resource-heavy, and a catalyst for innovation! üåêüí° #LLaMA #AILanguageModel #AIResearch #Innovation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate LinkedIn post\n",
    "\n",
    "from genaipy.prompts.generate_posts import GENERATE_POST_TPL\n",
    "\n",
    "generate_prompt = build_prompt(template=GENERATE_POST_TPL, text=styled_summary, max_words=150)\n",
    "\n",
    "post = get_chat_response(\n",
    "    prompt=generate_prompt,\n",
    "    sys_message=system_message,\n",
    "    temperature=0.5,\n",
    "    model=\"gpt-4-1106-preview\"\n",
    "    )\n",
    "\n",
    "Markdown(post)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
